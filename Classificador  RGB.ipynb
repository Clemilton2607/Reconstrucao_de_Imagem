{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "987d4fab",
   "metadata": {},
   "source": [
    "# Teste 02 - Classificador RGB \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "520e08e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from zipfile import ZipFile\n",
    "from tensorflow.keras.utils import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfdc6f1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(10)\n",
    "print(random.seed(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea4dcd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Vermelho: 100\n",
      "Train Azul: 100\n",
      "Train Verde: 100\n",
      "validation Vermelho: 12\n",
      "validation Azul: 10\n",
      "validation Verde: 7\n"
     ]
    }
   ],
   "source": [
    "# Baixando dataset e manipulando\n",
    "dataset_dir = os.path.join(os.getcwd(), r'C:\\Users\\Setup\\Downloads\\Classificador RGB')\n",
    "\n",
    "dataset_train_dir = os.path.join(dataset_dir, r'C:\\Users\\Setup\\Downloads\\Classificador RGB\\Train' )\n",
    "dataset_train_red_len = len(os.listdir(os.path.join(dataset_train_dir, r'C:\\Users\\Setup\\Downloads\\Classificador RGB\\Train\\vermelho')))\n",
    "dataset_train_blue_len = len(os.listdir(os.path.join(dataset_train_dir, r'C:\\Users\\Setup\\Downloads\\Classificador RGB\\Train\\azul')))\n",
    "dataset_train_green_len = len(os.listdir(os.path.join(dataset_train_dir, r'C:\\Users\\Setup\\Downloads\\Classificador RGB\\Train\\verde')))\n",
    "\n",
    "dataset_validation_dir = os.path.join(dataset_dir, r'C:\\Users\\Setup\\Downloads\\Classificador RGB\\Teste' )\n",
    "dataset_validation_red_len = len(os.listdir(os.path.join(dataset_validation_dir, r'C:\\Users\\Setup\\Downloads\\Classificador RGB\\Teste\\red')))\n",
    "dataset_validation_blue_len = len(os.listdir(os.path.join(dataset_validation_dir, r'C:\\Users\\Setup\\Downloads\\Classificador RGB\\Teste\\Blue')))\n",
    "dataset_validation_green_len = len(os.listdir(os.path.join(dataset_validation_dir, r'C:\\Users\\Setup\\Downloads\\Classificador RGB\\Teste\\Green')))\n",
    "\n",
    "print('Train Vermelho: %s' % dataset_train_red_len)\n",
    "print('Train Azul: %s' % dataset_train_blue_len)\n",
    "print('Train Verde: %s' % dataset_train_green_len)\n",
    "\n",
    "print('validation Vermelho: %s' % dataset_validation_red_len)\n",
    "print('validation Azul: %s' % dataset_validation_blue_len)\n",
    "print('validation Verde: %s' % dataset_validation_green_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c7f6366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 images belonging to 3 classes.\n",
      "Found 29 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "gerador_treinamento = ImageDataGenerator(rescale = 1./255,\n",
    "                                         rotation_range = 7, horizontal_flip = True,\n",
    "                                         shear_range = 0.2,\n",
    "                                         height_shift_range = 0.07, \n",
    "                                         zoom_range = 0.2)\n",
    "\n",
    "gerador_teste = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "base_treinamento = gerador_treinamento.flow_from_directory(r'C:\\Users\\Setup\\Downloads\\Classificador RGB\\Train',\n",
    "                                                           target_size = (150,150),\n",
    "                                                           batch_size = 32,\n",
    "                                                           class_mode='categorical')\n",
    "base_teste = gerador_teste.flow_from_directory(r'C:\\Users\\Setup\\Downloads\\Classificador RGB\\Teste',\n",
    "                                               target_size = (150,150),\n",
    "                                               batch_size = 32,\n",
    "                                               class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9bf31ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'azul': 0, 'verde': 1, 'vermelho': 2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_treinamento.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b056a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.regularization.dropout import Dropout\n",
    "# Rede Neural\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), activation = 'relu', input_shape= (150,150,3) ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(32,(3,3), activation = 'relu' , input_shape= (150,150,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(3, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08d3430d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/9 [================================] - ETA: 0s - loss: 1.2604 - accuracy: 0.8500WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 29 batches). You may need to use the repeat() function when building your dataset.\n",
      "9/9 [==============================] - 22s 2s/step - loss: 1.2604 - accuracy: 0.8500 - val_loss: 0.3075 - val_accuracy: 0.8276\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.7175 - accuracy: 0.9533\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.4516 - accuracy: 0.9800\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.6468 - accuracy: 0.9767\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.7229 - accuracy: 0.9767\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.3313 - accuracy: 0.9900\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.3322 - accuracy: 0.9800\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.4331 - accuracy: 0.9867\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.4077 - accuracy: 0.9833\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.3938 - accuracy: 0.9900\n"
     ]
    }
   ],
   "source": [
    "classificador =  model.fit(base_treinamento,steps_per_epoch = 300/32,\n",
    "          epochs = 10 , validation_data = base_teste,\n",
    "          validation_steps = 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00d1dc4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.2603739500045776,\n",
       "  0.7174530625343323,\n",
       "  0.4516100585460663,\n",
       "  0.6467602252960205,\n",
       "  0.722853422164917,\n",
       "  0.3312723934650421,\n",
       "  0.33218851685523987,\n",
       "  0.43305516242980957,\n",
       "  0.40769878029823303,\n",
       "  0.3937827944755554],\n",
       " 'accuracy': [0.8500000238418579,\n",
       "  0.95333331823349,\n",
       "  0.9800000190734863,\n",
       "  0.9766666889190674,\n",
       "  0.9766666889190674,\n",
       "  0.9900000095367432,\n",
       "  0.9800000190734863,\n",
       "  0.9866666793823242,\n",
       "  0.9833333492279053,\n",
       "  0.9900000095367432],\n",
       " 'val_loss': [0.30745062232017517],\n",
       " 'val_accuracy': [0.8275862336158752]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificador.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15674c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste com imagem Vermelha\n",
    "\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import tensorflow as tf\n",
    "image_teste = tf.keras.preprocessing.image.load_img(\n",
    "    r\"C:\\Users\\Setup\\Downloads\\ValidaçãoDataset RGB\\red.jpg\",\n",
    "    grayscale=False,\n",
    "    target_size=(150,150),\n",
    ")\n",
    "\n",
    "image_teste = tf.keras.utils.img_to_array(\n",
    "    image_teste, data_format=None, dtype=None\n",
    ")\n",
    "\n",
    "image_teste/= 255\n",
    "image_teste.astype('float32')\n",
    "image_teste = np.expand_dims(image_teste, axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8ceb9d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "Azul: 0.0\n",
      "Vermelho: 100.0\n",
      "Verde: 5.225591632143233e-36\n"
     ]
    }
   ],
   "source": [
    "previsao = model.predict(image_teste)\n",
    "pred = previsao[0]\n",
    "print('Azul:', pred[0]*100)\n",
    "print('Vermelho:', pred[2]*100)\n",
    "print('Verde:', pred[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66d8426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagem Azul\n",
    "\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import tensorflow as tf\n",
    "image_teste2 = tf.keras.preprocessing.image.load_img(\n",
    "    r\"C:\\Users\\Setup\\Downloads\\ValidaçãoDataset RGB\\green.jpg\",\n",
    "    grayscale=False,\n",
    "    target_size=(150,150),\n",
    ")\n",
    "\n",
    "image_teste2 = tf.keras.utils.img_to_array(\n",
    "    image_teste2, data_format=None, dtype=None\n",
    ")\n",
    "\n",
    "image_teste2/= 255\n",
    "image_teste2.astype('float32')\n",
    "image_teste2 = np.expand_dims(image_teste2, axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44ee7935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "Azul: 9.095688510638575e-23\n",
      "Vermelho: 1.2506706009912936e-33\n",
      "Verde: 100.0\n"
     ]
    }
   ],
   "source": [
    "previsao2 = model.predict(image_teste2)\n",
    "pred = previsao2[0]\n",
    "print('Azul:', pred[0]*100)\n",
    "print('Vermelho:', pred[2]*100)\n",
    "print('Verde:', pred[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c119942",
   "metadata": {},
   "source": [
    "# Teste 03 - Hiperparametros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0dd4c6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.regularization.dropout import Dropout\n",
    "# Rede Neural\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation = 'relu', input_shape= (150,150,3) ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3), activation = 'relu' , input_shape= (150,150,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(3, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "99b3fa28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/9 [================================] - ETA: 0s - loss: 4.2927 - accuracy: 0.8567WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 29 batches). You may need to use the repeat() function when building your dataset.\n",
      "9/9 [==============================] - 12s 1s/step - loss: 4.2927 - accuracy: 0.8567 - val_loss: 1.9734 - val_accuracy: 0.7586\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 10s 1s/step - loss: 1.7216 - accuracy: 0.9667\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 10s 1s/step - loss: 2.8119 - accuracy: 0.9533\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 10s 1s/step - loss: 3.3522 - accuracy: 0.9567\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.8853 - accuracy: 0.9767\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 10s 1s/step - loss: 2.1208 - accuracy: 0.9733\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.3000 - accuracy: 0.9833\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 10s 1s/step - loss: 1.4238 - accuracy: 0.9767\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 10s 1s/step - loss: 1.8744 - accuracy: 0.9500\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.3147 - accuracy: 0.9900\n"
     ]
    }
   ],
   "source": [
    "classificador =  model.fit(base_treinamento,steps_per_epoch = 300/32,\n",
    "          epochs = 10 , validation_data = base_teste,\n",
    "          validation_steps = 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "af893255",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.regularization.dropout import Dropout\n",
    "# Rede Neural\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128, (3,3), activation = 'relu', input_shape= (150,150,3) ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(128,(3,3), activation = 'relu' , input_shape= (150,150,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(3, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b8ba2113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 2.9279 - accuracy: 0.8967WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 29 batches). You may need to use the repeat() function when building your dataset.\n",
      "10/10 [==============================] - 23s 2s/step - loss: 2.9279 - accuracy: 0.8967 - val_loss: 0.5144 - val_accuracy: 0.7931\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 21s 2s/step - loss: 3.6824 - accuracy: 0.9500\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 22s 2s/step - loss: 4.1991 - accuracy: 0.9567\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 24s 2s/step - loss: 5.4968 - accuracy: 0.9500\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 23s 2s/step - loss: 2.3247 - accuracy: 0.9833\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 25s 2s/step - loss: 4.1105 - accuracy: 0.9567\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 23s 2s/step - loss: 3.0007 - accuracy: 0.9600\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.7137 - accuracy: 0.9767\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.5962 - accuracy: 0.9933\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 24s 2s/step - loss: 2.6529 - accuracy: 0.9733\n"
     ]
    }
   ],
   "source": [
    "classificador =  model.fit(base_treinamento,\n",
    "          epochs = 10 , validation_data = base_teste,\n",
    "          validation_steps = 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2d9b29e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 7s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 7s 2s/step - loss: 0.5050 - accuracy: 0.9896\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 7s 2s/step - loss: 0.0919 - accuracy: 0.9896\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 7s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 5s 2s/step - loss: 3.0384 - accuracy: 0.9868\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 7s 2s/step - loss: 0.2143 - accuracy: 0.9896\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 7s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 7s 3s/step - loss: 0.0677 - accuracy: 0.9868\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 7s 2s/step - loss: 1.0297 - accuracy: 0.9896\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 7s 3s/step - loss: 0.3168 - accuracy: 0.9792\n"
     ]
    }
   ],
   "source": [
    "classificador =  model.fit(base_treinamento,steps_per_epoch = 29/10,\n",
    "          epochs = 10 , validation_data = base_teste,\n",
    "          validation_steps = 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "775faada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste com imagem Vermelha\n",
    "\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import tensorflow as tf\n",
    "image_teste = tf.keras.preprocessing.image.load_img(\n",
    "    r\"C:\\Users\\Setup\\Downloads\\ValidaçãoDataset RGB\\e9bc32177168c518c3ce3506720febb91458235099_full.jpg\",\n",
    "    grayscale=False,\n",
    "    target_size=(150,150),\n",
    ")\n",
    "\n",
    "image_teste = tf.keras.utils.img_to_array(\n",
    "    image_teste, data_format=None, dtype=None\n",
    ")\n",
    "\n",
    "image_teste/= 255\n",
    "image_teste.astype('float32')\n",
    "image_teste = np.expand_dims(image_teste, axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8601cc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "Azul: 0.4695311654359102\n",
      "Vermelho: 1.5293196472284747e-24\n",
      "Verde: 99.53047037124634\n"
     ]
    }
   ],
   "source": [
    "previsao = model.predict(image_teste)\n",
    "pred = previsao[0]\n",
    "print('Azul:', pred[0]*100)\n",
    "print('Vermelho:', pred[2]*100)\n",
    "print('Verde:', pred[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e942a169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "Azul: 100.0\n",
      "Vermelho: 5.536023559039386e-29\n",
      "Verde: 5.502012842936988e-25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Imagem Azul\n",
    "\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import tensorflow as tf\n",
    "image_teste2 = tf.keras.preprocessing.image.load_img(\n",
    "    r\"C:\\Users\\Setup\\Downloads\\ValidaçãoDataset RGB\\maça.jpg\",\n",
    "    grayscale=False,\n",
    "    target_size=(150,150),\n",
    ")\n",
    "\n",
    "image_teste2 = tf.keras.utils.img_to_array(\n",
    "    image_teste2, data_format=None, dtype=None\n",
    ")\n",
    "\n",
    "image_teste2/= 255\n",
    "image_teste2.astype('float32')\n",
    "image_teste2 = np.expand_dims(image_teste2, axis = 0)\n",
    "\n",
    "previsao2 = model.predict(image_teste2)\n",
    "pred = previsao2[0]\n",
    "print('Azul:', pred[0]*100)\n",
    "print('Vermelho:', pred[2]*100)\n",
    "print('Verde:', pred[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc6c484",
   "metadata": {},
   "source": [
    "# Teste 04 - Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b201ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, Input\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from zipfile import ZipFile\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import random\n",
    "\n",
    "random.seed(10)\n",
    "print(random.seed(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1c6853a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train colorido: 3024\n",
      "Train Azul: 3024\n",
      "Teste colorido: 1295\n",
      "vTeste cinza: 1295\n"
     ]
    }
   ],
   "source": [
    "# Baixando dataset e manipulando\n",
    "dataset_dir = os.path.join(os.getcwd(), r'C:\\Users\\Setup\\Downloads\\Autoencoder - Copia')\n",
    "\n",
    "dataset_train_dir = os.path.join(dataset_dir, r'C:\\Users\\Setup\\Downloads\\Autoencoder - Copia\\train' )\n",
    "dataset_train_color_len = len(os.listdir(os.path.join(dataset_train_dir, r'C:\\Users\\Setup\\Downloads\\Autoencoder - Copia\\train\\colorido')))\n",
    "dataset_train_cinza_len = len(os.listdir(os.path.join(dataset_train_dir, r'C:\\Users\\Setup\\Downloads\\Autoencoder - Copia\\train\\cinza')))\n",
    "\n",
    "\n",
    "dataset_validation_dir = os.path.join(dataset_dir, r'C:\\Users\\Setup\\Downloads\\Autoencoder - Copia\\teste' )\n",
    "dataset_test_color_len = len(os.listdir(os.path.join(dataset_validation_dir, r'C:\\Users\\Setup\\Downloads\\Autoencoder - Copia\\teste\\colorido')))\n",
    "dataset_validation_blue_len = len(os.listdir(os.path.join(dataset_validation_dir, r'C:\\Users\\Setup\\Downloads\\Autoencoder - Copia\\teste\\cinza')))\n",
    "\n",
    "print('Train colorido: %s' % dataset_train_color_len)\n",
    "print('Train Azul: %s' % dataset_train_cinza_len)\n",
    "\n",
    "\n",
    "print('Teste colorido: %s' % dataset_test_color_len)\n",
    "print('vTeste cinza: %s' % dataset_validation_blue_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3704c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
